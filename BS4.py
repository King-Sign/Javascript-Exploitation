# # # # # # # # import requests
# # # # # # # # from pprint import pprint
# # # # # # # # def weather_data(query):
# # # # # # # # 	res=requests.get('http://api.openweathermap.org/data/2.5/weather?'+query+'&APPID=****************************8&units=metric');
# # # # # # # # 	return res.json();
# # # # # # # # def print_weather(result,city):
# # # # # # # # 	print("{}'s temperature: {}°C ".format(city,result['main']['temp']))
# # # # # # # # 	print("Wind speed: {} m/s".format(result['wind']['speed']))
# # # # # # # # 	print("Description: {}".format(result['weather'][0]['description']))
# # # # # # # # 	print("Weather: {}".format(result['weather'][0]['main']))
# # # # # # # # def main():
# # # # # # # # 	city=input('Enter the city:')
# # # # # # # # 	print()
# # # # # # # # 	try:
# # # # # # # # 	  query='q='+city;
# # # # # # # # 	  w_data=weather_data(query);
# # # # # # # # 	  print_weather(w_data, city)
# # # # # # # # 	  print()
# # # # # # # # 	except:
# # # # # # # # 	  print('City name not found...')
# # # # # # # # if __name__=='__main__':
# # # # # # # # 	main()
# # # # # # # from bs4 import BeautifulSoup
# # # # # # # html_doc = """
# # # # # # # <html>
# # # # # # # <head>
# # # # # # # <meta http-equiv="Content-Type" content="text/html;
# # # # # # # charset=iso-8859-1">
# # # # # # # <title>An example of HTML page</title>
# # # # # # # </head>
# # # # # # # <body>
# # # # # # # <h2>This is an example HTML page</h2>
# # # # # # # <p>
# # # # # # # Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc at nisi velit,
# # # # # # # aliquet iaculis est. Curabitur porttitor nisi vel lacus euismod egestas. In hac
# # # # # # # habitasse platea dictumst. In sagittis magna eu odio interdum mollis. Phasellus
# # # # # # # sagittis pulvinar facilisis. Donec vel odio volutpat tortor volutpat commodo.
# # # # # # # Donec vehicula vulputate sem, vel iaculis urna molestie eget. Sed pellentesque
# # # # # # # adipiscing tortor, at condimentum elit elementum sed. Mauris dignissim
# # # # # # # elementum nunc, non elementum felis condimentum eu. In in turpis quis erat
# # # # # # # imperdiet vulputate. Pellentesque mauris turpis, dignissim sed iaculis eu,
# # # # # # # euismod eget ipsum. Vivamus mollis adipiscing viverra. Morbi at sem eget nisl
# # # # # # # euismod porta.</p>
# # # # # # # <p><a href="https://www.w3resource.com/html/HTML-tutorials.php">Learn HTML from
# # # # # # # w3resource.com</a></p>
# # # # # # # <p><a href="https://www.w3resource.com/css/CSS-tutorials.php">Learn CSS from 
# # # # # # # w3resource.com</a></p>
# # # # # # # </body>
# # # # # # # </html>
# # # # # # # """
# # # # # # # soup = BeautifulSoup(html_doc, 'html.parser')
# # # # # # # print("The text in the first paragraph tag:")
# # # # # # # # print(soup.find_all('p')[1].text)
# # # # # # from urllib.request import urlopen
# # # # # # from bs4 import BeautifulSoup
# # # # # # import re

# # # # # # html = urlopen('https://en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer)')
# # # # # # bs = BeautifulSoup(html, 'html.parser')
# # # # # # images = bs.find_all('img', {'src':re.compile('.jpg')})
# # # # # # for image in images: 
# # # # # #     print(image['src']+'\n')
# # # # # #import random
# # # # # #counter=0
# # # # # #num=int(input("Think number between 1 and 50"))
# # # # # #counter=counter+1
# # # # # #while num!=25:
# # # # # #    if num<25:
# # # # # #       print("Your guess is low")
# # # # # #    else:
# # # # # #        print("Your guess is high")
# # # # # #    num=int(input("Make another guess"))
# # # # # #    counter+=1
# # # # # #print("Good job ! you guessed in ",counter, " guesses")
# # # # # import requests
# # # # # from bs4 import BeautifulSoup
# # # # # def imdb_top(imdb_top_n):
# # # # #     base_url = (
# # # # #         f"https://www.imdb.com/search/title?title_type="
# # # # #         f"feature&sort=num_votes,desc&count={imdb_top_n}"
# # # # #     )
# # # # #     source = BeautifulSoup(requests.get(base_url).content, "html.parser")
# # # # #     for m in source.findAll("div", class_="lister-item mode-advanced"):
# # # # #         print("\n" + m.h3.a.text)  # movie's name
# # # # #         print(m.find("span", attrs={"class": "genre"}).text)  # genre
# # # # #         print(m.strong.text)  # movie's rating
# # # # #         print(f"https://www.imdb.com{m.a.get('href')}")  # movie's page link
# # # # #         print("*" * 40)
# # # # # if __name__ == "__main__":
# # # # #     imdb_top(input("How many movies would you like to see? "))
# # # # import requests
# # # # from bs4 import BeautifulSoup

# # # # def get_citation(base_url: str, params: dict) -> str:
# # # #     """
# # # #     Return the citation number.
# # # #     """
# # # #     soup = BeautifulSoup(requests.get(base_url, params=params).content, "html.parser")
# # # #     div = soup.find("div", attrs={"class": "gs_ri"})
# # # #     anchors = div.find("div", attrs={"class": "gs_fl"}).find_all("a")
# # # #     return anchors[2].get_text()
# # # # if __name__ == "__main__":
# # # #     params = {
# # # #         "title": (
# # # #             "Precisely geometry controlled microsupercapacitors for ultrahigh areal "
# # # #             "capacitance, volumetric capacitance, and energy density"
# # # #         ),
# # # #         "journal": "Chem. Mater.",
# # # #         "volume": 30,
# # # #         "pages": "3979-3990",
# # # #         "year": 2018,
# # # #         "hl": "en",
# # # #     }
# # # #     print(get_citation("http://scholar.google.com/scholar_lookup", params=params))x
# # # #Source: https://bit.ly/3cepXbI
# # from collections import namedtuple
# # import requests
# # from lxml import html

# # covid_data = namedtuple("covid_data", "cases deaths recovered")
# # def covid_stats(url: str = "https://www.worldometers.info/coronavirus/") -> covid_data:
# #     xpath_str = '//div[@class = "maincounter-number"]/span/text()'
# #     return covid_data(*html.fromstring(requests.get(url).content).xpath(xpath_str))
# # fmt = """\nTotal COVID-19 cases in the world: {}
# # \nTotal deaths due to COVID-19 in the world: {}
# # \nTotal COVID-19 patients recovered in the world: {}"""
# # print(fmt.format(*covid_stats())) 
# # # import random
# # # answers = ['It is certain', 'It is decidedly so', 'Without a doubt', 'Yes – definitely', 'You may rely on it', 'As I see it, yes', 'Most likely', 'Outlook good', 'Yes Signs point to yes', 'Reply hazy', 'try again', 'Ask again later', 'Better not tell you now', 'Cannot predict now', 'Concentrate and ask again', 'Dont count on it', 'My reply is no', 'My sources say no', 'Outlook not so good', 'Very doubtful']

# # # print('  __  __     _     _____ _____ _____   __  ')
# # # print(' |  \/  |   /\   / ____|_   _/ ____|  / _ \ ')
# # # print(' | \  / |  /  \ | |  __  | || |      | (_) |')
# # # print(' | |\/| | / /\ \| | |_ | | || |       > _ < ')
# # # print(' | |  | |/ ____ \ |__| |_| || |____  | (_) |')
# # # print(' |_|  |_/_/    \_\_____|_____\_____|  \___/ ')
# # # print('')
# # # print('')
# # # print('')
# # # print('Hello World, I am the Magic 8 Ball, What is your name?')
# # # name = input()
# # # print('hello ' + name)


# # # def Magic8Ball():
# # #     print('Ask me a question.')
# # #     input()
# # #     print (answers[random.randint(0, len(answers)-1)] )
# # #     print('I hope that helped!')
# # #     Replay()
    

# # # def Replay():
# # #     print ('Do you have another question? [Y/N] ')
# # #     reply = input()
# # #     if reply == 'Y':
# # #         Magic8Ball()
# # #     elif reply == 'N':
# # #         exit()
# # #     else:
# # #         print('I apologies, I did not catch that. Please repeat.')
# # #         Replay()

		
# # # Magic8Ball()
# from __future__ import annotations
# import csv
# import requests
# from bs4 import BeautifulSoup

# def get_imdb_top_250_movies(url: str = "") -> dict[str, float]:
#     url = url or "https://www.imdb.com/chart/top/?ref_=nv_mv_250"
#     soup = BeautifulSoup(requests.get(url).text, "html.parser")
#     titles = soup.find_all("td", attrs="titleColumn")
#     ratings = soup.find_all("td", class_="ratingColumn imdbRating")
#     return {
#         title.a.text: float(rating.strong.text)
#         for title, rating in zip(titles, ratings)
#     }
# def write_movies(filename: str = "IMDb_Top_250_Movies.csv") -> None:
#     movies = get_imdb_top_250_movies()
#     print("Movie Title and Rating:\n")
#     with open(filename, "w", newline="") as out_file:
#         writer = csv.writer(out_file)
#         writer.writerow(["Movie title", "IMDb rating"])
#         for title, rating in movies.items():
#             print(title," ",rating)
#             writer.writerow([title, rating])
# if __name__ == "__main__":
#     write_movies()
import time
Birthdays ={
    "Durga Pokharel": "",
    "Barsha Bhandari": "28/10/1998",
    "Crystal Bhattarai": "24/2/2015",
    "Shubekshya Pandey":"13/2/2012",
}
print("Welcome to the Birthday special. Please wish  person who have birthday ! We have the birthdays to:")
time.sleep(1)
for x in Birthdays:
    print(x)
    time.sleep(0.7)
choice= input("\nWho's birthday do you want to look up?")

if choice in Birthdays:
    print("The birthday of {} is: ".format(choice))
    print(Birthdays[choice])